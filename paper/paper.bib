@inbook{Pisinger_Ropke:2010,
    title = "Large Neighborhood Search",
    abstract = "Heuristics based on large neighborhood search have recently shown outstanding results in solving various transportation and scheduling problems. Large neighborhood search methods explore a complex neighborhood by use of heuristics. Using large neighborhoods makes it possible to find better candidate solutions in each iteration and hence traverse a more promising search path. Starting from the large neighborhood search method,we give an overview of very large scale neighborhood search methods and discuss recent variants and extensions like variable depth search and adaptive large neighborhood search.",
    author = "David Pisinger and Stefan R{\o}pke",
    year = "2010",
    isbn = "978-1-4419-1663-1",
    pages = "399--420",
    editor = "Michel Gendreau",
    booktitle = "Handbook of Metaheuristics",
    publisher = "Springer",
    DOI = {10.1007/978-1-4419-1665-5_13},
    edition = "2",
}

@article{Santini_et_al:2018,
    title={A comparison of acceptance criteria for the adaptive large neighbourhood search metaheuristic},
    volume={24},
    ISSN={1572-9397},
    DOI={10.1007/s10732-018-9377-x},
    abstractNote={Adaptive large neighborhood search (ALNS) is a useful framework for solving difficult combinatorial optimisation problems. As a metaheuristic, it consists of some components that must be tailored to the specific optimisation problem that is being solved, while other components are problem independent. The literature is sparse with respect to studies that aim to evaluate the relative merit of different alternatives for specific problem independent components. This paper investigates one such component, the move acceptance criterion in ALNS, and compares a range of alternatives. Through extensive computational testing, the alternative move acceptance criteria are ranked in three groups, depending on the performance of the resulting ALNS implementations. Among the best variants, we find versions of criteria based on simulated annealing, threshold acceptance, and record-to-record travel, with a version of the latter being consistently undominated by the others. Additional analyses focus on the search behavior, and multiple linear regression is used to identify characteristics of search behavior that are associated with good search performance.},
    number={5},
    journal={Journal of Heuristics},
    author={Santini, Alberto and R{\o}pke, Stefan and Hvattum, Lars Magnus},
    year={2018},
    pages={783--815},
}

@article{Ropke_Pisinger:2006,
    author = {Stefan R{\o}pke and David Pisinger},
    journal = {Transportation Science},
    number = {4},
    pages = {455--472},
    DOI = {10.1287/trsc.1050.0135},
    title = {An adaptive large neighborhood search heuristic for the pickup and delivery problem with time windows},
    volume = {40},
    year = {2006}
}

@article{Windras_Mara_et_al:2022,
    title = {A survey of adaptive large neighborhood search algorithms and applications},
    volume = {146},
    ISSN = {0305-0548},
    DOI = {10.1016/j.cor.2022.105903},
    abstractNote = {This article provides a survey on the highly popular metaheuristic framework, the adaptive large neighborhood search (ALNS). The basic concepts of ALNS are discussed in this paper. Based on a simple taxonomy, the analysis of publication intensity, application areas, and the variant of ALNS features are executed on 252 scientific publications to synthesize the state-of-the-art of ALNS research. Finally, some discussions on the future research of ALNS are provided.},
    journal = {Computers & Operations Research},
    author = {Windras Mara, Setyo Tri and Norcahyo, Rachmadi and Jodiawan, Panca and Lusiantoro, Luluk and Rifai, Achmad Pratama},
    year = {2022},
    pages = {105903},
}

@misc{Reijnen_et_al:2022,
    doi = {10.48550/arxiv.2211.00759},
    url = {https://arxiv.org/abs/2211.00759},
    author = {Reijnen, Robbert and Zhang, Yingqian and Lau, Hoong Chuin and Bukhsh, Zaharah},
    title = {Operator Selection in Adaptive Large Neighborhood Search using Deep Reinforcement Learning},
    publisher = {arXiv},
    year = {2022},
}

@article{Wouda_et_al:2022,
    title={An adaptive large neighbourhood search metaheuristic for hourly learning activity planning in personalised learning},
    ISSN={0305-0548},
    DOI={10.1016/j.cor.2022.106089},
    abstractNote={Personalised learning offers an alternative method to one-size-fits-all education in schools, and has seen increasing adoption over the past several years. Personalised learning’s focus on learner-driven education requires novel scheduling methods. In this paper we introduce the hourly, learner-driven activity planning problem of personalised learning, and formulate scheduling methods to solve it. We present an integer linear programming model of the problem, but this model does not generate schedules sufficiently quickly for use in practice. To overcome this, we propose an adaptive large neighbourhood search metaheuristic to solve the problem instead. The metaheuristic’s performance is compared against optimal solutions in a large numerical study of 14,400 instances. These instances are representative of secondary education in the Netherlands, and were developed from expert opinions. Solutions on average deviate only 1.6% from optimal results. Further, our experiments numerically demonstrate the mitigating effects changes to the structure and staffing of secondary education have on the challenges of satisfying learner instruction demands in personalised learning.},
    journal={Computers & Operations Research},
    author={Wouda, Niels A. and Aslan, Ayse and Vis, Iris F. A.},
    year={2022},
    pages={106089},
}

@article{vidal:2022,
    title = {Hybrid genetic search for the CVRP: Open-source implementation and SWAP* neighborhood},
    journal = {Computers & Operations Research},
    volume = {140},
    pages = {105643},
    year = {2022},
    issn = {0305-0548},
    doi = {10.1016/j.cor.2021.105643},
    url = {https://www.sciencedirect.com/science/article/pii/S030505482100349X},
    author = {Thibaut Vidal},
    abstract = {The vehicle routing problem is one of the most studied combinatorial optimization topics, due to its practical importance and methodological interest. Yet, despite extensive methodological progress, many recent studies are hampered by the limited access to simple and efficient open-source solution methods. Given the sophistication of current algorithms, reimplementation is becoming a difficult and time-consuming exercise that requires extensive care for details to be truly successful. Against this background, we use the opportunity of this short paper to introduce a simple – open-source – implementation of the hybrid genetic search (HGS) specialized to the capacitated vehicle routing problem (CVRP). This state-of-the-art algorithm uses the same general methodology as Vidal et al. (2012) but also includes additional methodological improvements and lessons learned over the past decade of research. In particular, it includes an additional neighborhood called SWAP* which consists in exchanging two customers between different routes without an insertion in place. As highlighted in our study, an efficient exploration of SWAP* moves significantly contributes to the performance of local searches. Moreover, as observed in experimental comparisons with other recent approaches on the classical instances of Uchoa et al. (2017), HGS still stands as a leading metaheuristic regarding solution quality, convergence speed, and conceptual simplicity.}
}

@article{Dueck:1993,
    title={New Optimization Heuristics: The Great Deluge Algorithm and the Record-to-Record Travel},
    volume={104},
    ISSN={0021-9991},
    DOI={10.1006/jcph.1993.1010},
    abstractNote={In a former paper we introduced a very effective new general purpose optimization principle. We compared this method, which we called threshold accepting (TA), with the well-known simulated annealing (SA) method for discrete optimization. The empirical results demonstrated the superiority of the TA algorithm. In further experiments with the TA principle we discovered two new powerful optimization heuristics: The great deluge algorithm (GDA) and the record-to-record travel (RRT). These algorithms resemble in their structure the formerly studied TA and the SA method. The differences lie in their acceptance rules for worse intermediate solutions. Both, the GDA and the RRT, are essentially one-parameter algorithms; i.e., for the achievement of best possible performance, a good choice is necessary only for a single parameter. This is in contrast for instance to the classical AS algorithm, where it is necessary to choose carefully a certain sequence of parameters, the so-called annealing schedule. The quality of the computational results obtained so far by RRT and GDA shows that the new algorithms behave equally well as TA and thus a fortiori better than SA.},
    number={1},
    journal={Journal of Computational Physics},
    author={Dueck, Gunter},
    year={1993},
    pages={86–92},
}

@article{Hendel:2022,
    title={Adaptive large neighborhood search for mixed integer programming},
    volume={14},
    ISSN={1867-2957},
    DOI={10.1007/s12532-021-00209-7},
    abstractNote={Large Neighborhood Search (LNS) heuristics are among the most powerful but also most expensive heuristics for mixed integer programs (MIP). Ideally, a solver adaptively concentrates its limited computational budget by learning which LNS heuristics work best for the MIP problem at hand. To this end, this work introduces Adaptive Large Neighborhood Search (ALNS) for MIP, a primal heuristic that acts as a framework for eight popular LNS heuristics such as Local Branching and Relaxation Induced Neighborhood Search (RINS). We distinguish the available LNS heuristics by their individual search spaces, which we call auxiliary problems. The decision which auxiliary problem should be executed is guided by selection strategies for the multi armed bandit problem, a related optimization problem during which suitable actions have to be chosen to maximize a reward function. In this paper, we propose an LNS-specific reward function to learn to distinguish between the available auxiliary problems based on successful calls and failures. A second, algorithmic enhancement is a generic variable fixing prioritization, which ALNS employs to adjust the subproblem complexity as needed. This is particularly useful for some LNS problems which do not fix variables by themselves. The proposed primal heuristic has been implemented within the MIP solver SCIP. An extensive computational study is conducted to compare different LNS strategies within our ALNS framework on a large set of publicly available MIP instances from the MIPLIB and Coral benchmark sets. The results of this simulation are used to calibrate the parameters of the bandit selection strategies. A second computational experiment shows the computational benefits of the proposed ALNS framework within the MIP solver SCIP.},
    number={2},
    journal={Mathematical Programming Computation},
    author={Hendel, Gregor},
    year={2022},
    pages={185–221},
}

@article{Swan_et_al:2022,
    title={Metaheuristics “In the Large”},
    volume={297},
    ISSN={0377-2217},
    DOI={10.1016/j.ejor.2021.05.042},
    abstractNote={Following decades of sustained improvement, metaheuristics are one of the great success stories of optimization research. However, in order for research in metaheuristics to avoid fragmentation and a lack of reproducibility, there is a pressing need for stronger scientific and computational infrastructure to support the development, analysis and comparison of new approaches. To this end, we present the vision and progress of the Metaheuristics “In the Large” project. The conceptual underpinnings of the project are: truly extensible algorithm templates that support reuse without modification, white box problem descriptions that provide generic support for the injection of domain specific knowledge, and remotely accessible frameworks, components and problems that will enhance reproducibility and accelerate the field’s progress. We argue that, via such principled choice of infrastructure support, the field can pursue a higher level of scientific enquiry. We describe our vision and report on progress, showing how the adoption of common protocols for all metaheuristics can help liberate the potential of the field, easing the exploration of the design space of metaheuristics.},
    number={2},
    journal={European Journal of Operational Research},
    author={Swan, Jerry and Adriaensen, Steven and Brownlee, Alexander E. I. and Hammond, Kevin and Johnson, Colin G. and Kheiri, Ahmed and Krawiec, Faustyna and Merelo, J. J. and Minku, Leandro L. and Özcan, Ender and Pappa, Gisele L. and García-Sánchez, Pablo and Sörensen, Kenneth and Voß, Stefan and Wagner, Markus and White, David R.},
    year={2022},
    pages={393–406},
}

@article{Fortin2012-DEAPEvolutionaryAlgorithms,
  title = {{{DEAP}}: {{Evolutionary Algorithms Made Easy}}},
  shorttitle = {{{DEAP}}},
  author = {Fortin, F{\'e}lix-Antoine and Rainville, Fran{\c c}ois-Michel De and Gardner, Marc-Andr{\'e} and Parizeau, Marc and Gagn{\'e}, Christian},
  year = {2012},
  journal = {Journal of Machine Learning Research},
  volume = {13},
  number = {70},
  pages = {2171--2175},
  issn = {1533-7928},
  abstract = {DEAP is a novel evolutionary computation framework for rapid prototyping and testing of ideas. Its design departs from most other existing frameworks in that it seeks to make algorithms explicit and data structures transparent, as opposed to the more common black-box frameworks. Freely available with extensive documentation at http://deap.gel.ulaval.ca, DEAP is an open source project under an LGPL license.},
}

@inproceedings{Scott2019-ECJ20General,
  title = {{{ECJ}} at 20: Toward a General Metaheuristics Toolkit},
  shorttitle = {{{ECJ}} at 20},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference Companion}}},
  author = {Scott, Eric O. and Luke, Sean},
  year = {2019},
  month = jul,
  series = {{{GECCO}} '19},
  pages = {1391--1398},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3319619.3326865},
  abstract = {ECJ is now 20 years old. Begun as a genetic programming and evolutionary computation library in Java, it has since established itself as historically one of the most popular EC toolkits worldwide. In 2016 we received a National Science Foundation grant to improve ECJ in many ways with an eye toward making it a useful toolkit not just for EC but for the broader metaheuristics community. This paper is a report on our efforts to this end. We discuss new metaheuristics frameworks and representations added to ECJ and the design challenges that they raise for a general-purpose framework, as well as testing facilities and other support tools. We conclude with our future directions for the library.},
  isbn = {978-1-4503-6748-6},
}

@article{Durillo2011-JMetalJavaFramework,
  title = {{{jMetal}}: {{A Java}} Framework for Multi-Objective Optimization},
  shorttitle = {{{jMetal}}},
  author = {Durillo, Juan J. and Nebro, Antonio J.},
  year = {2011},
  month = oct,
  journal = {Advances in Engineering Software},
  volume = {42},
  number = {10},
  pages = {760--771},
  issn = {0965-9978},
  doi = {10.1016/j.advengsoft.2011.05.014},
  abstract = {This paper describes jMetal, an object-oriented Java-based framework aimed at the development, experimentation, and study of metaheuristics for solving multi-objective optimization problems. jMetal includes a number of classic and modern state-of-the-art optimizers, a wide set of benchmark problems, and a set of well-known quality indicators to assess the performance of the algorithms. The framework also provides support to carry out full experimental studies, which can be configured and executed by using jMetal's graphical interface. Other features include the automatic generation of statistical information of the obtained results, and taking advantage of the current availability of multi-core processors to speed-up the running time of the experiments. In this work, we include two case studies to illustrate the use of jMetal in both solving a problem with a metaheuristic and designing and performing an experimental study.},
  language = {en},
}

@inproceedings{Dreo2021-ParadiseoModularFramework,
  title = {Paradiseo: From a Modular Framework for Evolutionary Computation to the Automated Design of Metaheuristics: 22 Years of {{Paradiseo}}},
  shorttitle = {Paradiseo},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference Companion}}},
  author = {Dreo, Johann and Liefooghe, Arnaud and Verel, S{\'e}bastien and Schoenauer, Marc and Merelo, Juan J. and Quemy, Alexandre and Bouvier, Benjamin and Gmys, Jan},
  year = {2021},
  month = jul,
  series = {{{GECCO}} '21},
  pages = {1522--1530},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3449726.3463276},
  abstract = {The success of metaheuristic optimization methods has led to the development of a large variety of algorithm paradigms. However, no algorithm clearly dominates all its competitors on all problems. Instead, the underlying variety of landscapes of optimization problems calls for a variety of algorithms to solve them efficiently. It is thus of prior importance to have access to mature and flexible software frameworks which allow for an efficient exploration of the algorithm design space. Such frameworks should be flexible enough to accommodate any kind of metaheuristics, and open enough to connect with higher-level optimization, monitoring and evaluation softwares. This article summarizes the features of the Paradiseo framework, a comprehensive C++ free software which targets the development of modular metaheuristics. Paradiseo provides a highly modular architecture, a large set of components, speed of execution and automated algorithm design features, which are key to modern approaches to metaheuristics development.},
  isbn = {978-1-4503-8351-6},
}

@article{Mejia-de-Dios2022-MetaheuristicsJuliaPackage,
  title = {Metaheuristics: {{A Julia Package}} for {{Single-}} and {{Multi-Objective Optimization}}},
  shorttitle = {Metaheuristics},
  author = {{Mej{\'i}a-de-Dios}, Jes{\'u}s-Adolfo and {Mezura-Montes}, Efr{\'e}n},
  year = {2022},
  month = oct,
  journal = {Journal of Open Source Software},
  volume = {7},
  number = {78},
  pages = {4723},
  issn = {2475-9066},
  doi = {10.21105/joss.04723},
  abstract = {Mej\'ia-de-Dios et al., (2022). Metaheuristics: A Julia Package for Single- and Multi-Objective Optimization. Journal of Open Source Software, 7(78), 4723, https://doi.org/10.21105/joss.04723},
  language = {en},
}

@article{Parejo2012-MetaheuristicOptimizationFrameworks,
  title = {Metaheuristic Optimization Frameworks: A Survey and Benchmarking},
  shorttitle = {Metaheuristic Optimization Frameworks},
  author = {Parejo, Jos{\'e} Antonio and {Ruiz-Cort{\'e}s}, Antonio and Lozano, Sebasti{\'a}n and Fernandez, Pablo},
  year = {2012},
  month = mar,
  journal = {Soft Computing},
  volume = {16},
  number = {3},
  pages = {527--561},
  issn = {1432-7643, 1433-7479},
  doi = {10.1007/s00500-011-0754-8},
  language = {en},
}

@article{Cicirello2020-ChipsnSalsaJavaLibrary,
  title = {Chips-n-{{Salsa}}: {{A Java Library}} of {{Customizable}}, {{Hybridizable}}, {{Iterative}}, {{Parallel}}, {{Stochastic}}, and {{Self-Adaptive Local Search Algorithms}}},
  shorttitle = {Chips-n-{{Salsa}}},
  author = {Cicirello, Vincent A.},
  year = {2020},
  month = aug,
  journal = {Journal of Open Source Software},
  volume = {5},
  number = {52},
  pages = {2448},
  issn = {2475-9066},
  doi = {10.21105/joss.02448},
  abstract = {Cicirello, V. A., (2020). Chips-n-Salsa: A Java Library of Customizable, Hybridizable, Iterative, Parallel, Stochastic, and Self-Adaptive Local Search Algorithms. Journal of Open Source Software, 5(52), 2448, https://doi.org/10.21105/joss.02448},
  language = {en},
}

@misc{Santini2019-AdaptiveLargeNeighbourhood,
  title = {Adaptive {{Large Neighbourhood Search}}},
  author = {Santini, Alberto},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/alberto-santini/adaptive-large-neighbourhood-search}},
  abstract = {ALNS header-only library (loosely) based on the original implementation by Stefan Ropke.},
}

@article{Miranda2018-PySwarmsResearchToolkit,
  title = {{{PySwarms}}: A Research Toolkit for {{Particle Swarm Optimization}} in {{Python}}},
  shorttitle = {{{PySwarms}}},
  author = {Miranda, Lester James},
  year = {2018},
  month = jan,
  journal = {Journal of Open Source Software},
  volume = {3},
  number = {21},
  pages = {433},
  issn = {2475-9066},
  doi = {10.21105/joss.00433},
  abstract = {Miranda, (2018). PySwarms: a research toolkit for Particle Swarm Optimization in Python. Journal of Open Source Software, 3(21), 433, https://doi.org/10.21105/joss.00433},
  language = {en},
}
